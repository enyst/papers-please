# Interesting Blog Posts

## 2025-11-02 - [What if you dont need MCP at all?](https://mariozechner.at/posts/2025-11-02-what-if-you-dont-need-mcp/)
Mario Zechner argues that many MCP servers add dozens of tools, long descriptions, and brittle abstractions that waste context and are hard to extend. He shows that equipping an agent with a handful of Bash- and Node-driven browser tools (start Chrome, navigate, evaluate JS, take screenshots, pick DOM nodes, grab cookies) built on Puppeteer gives composable, debuggable functionality without the MCP overhead. The post includes concrete scripts, token cost comparisons, and guidance on packaging these utilities so any coding agent can invoke them like ordinary CLI commands.

## 2025-10-20 - [Agentic AIs OODA Loop Problem](https://www.schneier.com/blog/archives/2025/10/agentic-ais-ooda-loop-problem.html)
Bruce Schneier applies the observe-orient-decide-act framework to AI agents and stresses that their "observe" and "orient" steps are inherently untrustworthy in adversarial environments. Because agents ingest tool outputs, documents, and sensors that can be maliciously crafted, their downstream decisions remain fragile even if the models reasoning improves. Schneier calls for systems-level safeguards that ensure input, processing, and output integrity, not just smarter policies, if we expect autonomous agents to operate safely against motivated attackers.

## 2025-06-02 - [Prompts are code, .json/.md files are state](https://mariozechner.at/posts/2025-06-02-prompts-are-code/)
Zechner describes treating an LLM session as a deterministic computer program: prompts encode the "code," JSON and Markdown files hold persistent state, and tools act as I/O. He illustrates the pattern by porting complex Spine runtime changes, where the agent follows a scripted loop, loads only the necessary files into context, records progress to porting-plan.json, and enforces human checkpoints. The takeaway is that reproducible workflows beat ad-hoc chatting, dramatically reducing the time and fragility of large-scale code modifications.

## 2025-07-19 - [Why Arent We Making Any Progress In Security From AI](https://www.mbgsec.com/posts/2025-07-19-data-flow-controls-wont-save-us/)
Michael Bargury distinguishes between hard boundaries (enforced in software, such as VM sandboxes or UI constraints) and soft boundaries (LLM guardrails or instruction hierarchies). Soft boundaries are cheap to deploy but inherently bypassable because they rely on statistical behavior; attackers only need the rare failure case. He catalogs recent examples where vendors removed hard boundaries to preserve functionality and urges builders to enforce strict dataflow controls, so agents simply cannot trigger dangerous follow-on actions, instead of trusting ever more "robust" prompt training.
